\section{Euclidean Domains, Principal Ideal Domains, and Unique Factorization Domains}

\hl{All rings in this section are commutative.}

\nl

\begin{defn}
Any function $N:R\ra \Z_{\geq 0}$ with $N(0) = 0$ is called a \textit{\textbf{norm}} on the integral domain $R$. If $N(a)> 0$ for all $a\neq 0$ define $N$ to be a \textit{positive norm}.
\end{defn}

\nl

\begin{defn}
The integral domain $R$ is said to be a \hl{\textit{\textbf{Euclidean Domain}}} if there is a norm $N$ on $R$ such that for any two elements $a$ and $b$ of $R$ with $b\neq 0$ there exist elements $q$ and $r$ in $R$ with 
\[a = qb + r\qquad \text{with } r = 0 \text{ or } N(r)<N(b).\]
\end{defn}

\nl

\begin{defn}
Let $R$ be a commutative ring and let $a,b\in R$ with $b\neq 0$.
\begin{enumerate}
\item $a$ is said to be a \textbf{\textit{multiple}} of $b$ if $a = bx$ for some $x\in R$. In this case $b$ is said to divide or be a divisor of $a$, written $b\ |\ a$.
\item A \textbf{\textit{greatest common divisor}} of $a$ and $b$ is a nonzero element $d$ such that 
\begin{enumerate}
\item $d\ |\ a$ and $d\ |\ b$, and 
\item if $d^\p\ |\ a$ and $d^\p\ |\ b$ then $d\ |\ d^\p$.
\end{enumerate}
A greatest common divisor of $a$ and $b$ will be denoted by $\gcd(a,b)$.
\end{enumerate}
\end{defn}

\nl

\begin{prop}
If $a$ and $b$ are nonzero elements in the commutative ring $R$ such that the ideal generated by $a$ and $b$ is a principal ideal $(d)$, then $d$ is a greatest common divisor of $a$ and $b$.
\end{prop}

\nl

\begin{prop}
Let $R$ be an integral domain. If two elements $d$ and $d^\p$ of $R$ generate the same principal ideal, then $d^\p = ud$ for some unit $u\in R$. In particular, if $d$ and $d^\p$ are both greatest common divisors of $a$ and $b$, then $d^\p = ud$ for some unit $u$.
\end{prop}

\nl

\begin{thm}
Let $R$ be a Euclidean Domain and let $a$ and $b$ be nonzero elements of $R$. Let $d = r_n$ be the last nonzero remainder in the Euclidean Algorithm for $a$ and $b$. Then
\begin{enumerate}
\item $d$ is a greatest common divisor of $a$ and $b$, and 
\item the principal ideal $(d)$ is the ideal generated by $a$ and $b$. In particular, $d$ can be written as an $R$\textbf{\textit{-linear combination}} of $a$ and $b$, i.e., there are elements $x$ and $y$ in $R$ such that 
\[d = ax + by.\]
\end{enumerate}
\end{thm}

\nl

\begin{defn}
A domain $R$ in which every ideal is principal is called a \textbf{\textit{Principal Ideal Domain}} (PID).
\end{defn}

\nl

\begin{prop}
Let $R$ be a PID and let $a$ and $b$ be nonzero elements of $R$. Let $d$ be a generator for the principal ideal generated by $a$ and $b$. Then
\begin{enumerate}
\item $d$ is a greatest common divisor of $a$ and $b$
\item $d$ can be written as an $R$-\textit{linear combination} of $a$ and $b$, i.e., there are elements $x$ and $y$ in $R$ with 
\[d = ax + by\]
\item $d$ is unique up to multiplication by a unit in $R$.
\end{enumerate}
\end{prop}

\nl

\begin{prop}
\hl{Every nonzero prime ideal in a PID is a maximal ideal.} 
\end{prop}

\nl

\begin{cor}
If $R$ is any commutative ring such that the polynomial ring $R[x]$ is a PID (or Euclidean Domain), then $R$ is necessarily a field.
\end{cor}

\nl

\begin{defn}
Let $R$ be an integral domain
\begin{enumerate}
\item Suppose $r\in R$ is nonzero and is not a unit. Then $r$ is called \textit{\textbf{irreducible}} if $R$ if whenever $r = ab$ with $a,b\in R$ at least one of $a$ or $b$ is a unit in $R$.
\item The nonzero element $p\in R$ is called \textbf{\textit{prime}} in $R$ it the ideal $(p)$ generated by $p$ is a prime ideal. In other words, for any $a,b\in R$ if $p\ |\ ab$ then either $p\ |\ a$ or $p\ |\ b$.
\item Two elements $a,b\in R$ differing by a unit are said to be \textit{\textbf{associate}} in $R$.
\end{enumerate}
\end{defn}

\nl

\begin{prop}
\hl{In an integral domain a prime element is always irreducible.}
\end{prop}

\nl

\begin{prop}
In a PID a nonzero element is prime if and only if it is irreducible.
\end{prop}

\nl

\begin{defn}
A \hl{\textit{\textbf{Unique Factorization Domain (UFD)}}} is an integral domain $R$ in which every nonzero element $r\in R$ which is not a unit has the following two properties:
\begin{enumerate}
\item $r$ can be written as the finite product of irreducibles $p_i$ of $R$: $r = p_1p_2\cdots p_n$ and
\item the decomposition given in (1) is unique up to associates. 
\end{enumerate}
\end{defn}

\nl

\begin{prop}
\hl{In a UFD a nonzero element is a prime if and only if it is irreducible.}
\end{prop}

\nl

\begin{prop}
Let $a$ and $b$ be two nonzero elements of the UFD $R$ and suppose
\[a = u\ p_1^{e_1}p_2^{e_2}p_3^{e_3}\cdots p_n^{e_n}\qquad\text{and}\qquad b = v\ p_1^{f_1}p_2^{f_2}p_3^{f_3}\cdots p_n^{f_n}\]
are prime factorizations for $a$ and $b$, where $u$ and $v$ are units, the primes $p_1,p_2,\ldots,p_n$ are \textit{distinct} and the exponents $e_i$ and $f_i$ are $\geq 0$. Then the element 
\[d = p_1^{\min(e_1,f_1)}p_2^{\min(e_2,f_2)}p_3^{\min(e_3,f_3)}\cdots p_n^{\min(e_n,f_n)}\]
is a greatest common divisor of $a$ and $b$. 
\end{prop}

\nl

\begin{thm}
Every PID is a UFD. In particular, every Euclidean Domain is a UFD. 
\end{thm}

\nl

\begin{lem}
The prime number $p\in \Z$ divides an integer of the form $n^2 + 1$ if and only if $p$ is either 2 or is an odd prime congruent to $1\mod 4$.
\end{lem}

\nl

\begin{prop}\nl
\begin{enumerate}
\item \textit{(Fermat's Theorem on sums of squares)} The prime $p$ is the sum of two integer squares, $p = a^2 + b^2$ if and only if $p = 2$ or $p\equiv 1\mod 4$. Except for the interchanging $a$ and $b$, the representation of $p$ as the sum of two squares is unique. 
\item The irreducible elements in the Gaussian integers $\Z[i]$ are as follows
\begin{enumerate}
\item $1 + i$
\item the primes $p\in \Z$ with $p\equiv 3\mod 4$
\item $a + bi,\ a-bi$, the distinct irreducible factors of $p = a^2 + b^2$ for the primes $p\in \Z$ with $p\equiv 1\mod 4$.
\end{enumerate}
\end{enumerate}
\end{prop}


%################################################################################
\section{Polynomial Rings}
\setcounter{thm}{0}

\begin{prop}
Let $I$ be an ideal of $R$ and let $(I) = I[x]$ denote the ideal of $R[x]$ generated by $I$. Then 
\[R[x]/(I) \cong (R/I)[x].\]
In particular, if $I$ is a prime ideal of $R$ then (I) is a prime ideal of $R[x]$
\end{prop}

\nl

\begin{defn}
The \textit{polynomial ring in the variables} $x_1,x_2,\ldots,x_n$ \textit{with coefficients in $R$}, denoted $R[x_1,x_2,\ldots,x_n]$, is defined inductively by
\[R[x_1,x_2,\ldots,x_n] = R[x_1,x_2,\ldots,x_{n-1}][x_n]\]
\end{defn}

\nl

\begin{thm}
Let $F$ be a field. The polynomial ring $F[x]$ is a Euclidean Domain. Specifically, if $a(x)$ and $b(x)$ are two polynomials in $F[x]$ with $b(x)$ nonzero, the there are \textit{unique} $q(x)$ and $r(x)$ in $F[x]$ such that
\[a(x) = q(x)b(x) + r(x)\qquad\text{with } r(x) = 0\text{ or } deg(r(x))<deg(b(x)).\]
\end{thm}

\nl

\begin{prop}\hl{\textit{(Gauss' Lemma)}} Let $R$ be a UFD with field of fractions $F$ and let $p(x)\in R[x]$. If $p(x)$ is reducible in $F[x]$ then $p(x)$ is reducible in $R[x]$. More precisely, if $p(x) = A(x)B(x)$ for some nonconstant polynomials $A(x),B(x)\in F[x]$, then there are some nonzero elements $r,s\in F$ such that $rA(x) = a(x)$ and $sB(x) = b(x)$ both lie in $R[x]$ and $p(x) = a(x)b(x)$ is a factorization in $R[x]$.
\end{prop}

\nl

\begin{cor}
Let $R$ be a UFD, let $F$ be its field of fractions and let $p(x)\in R[x]$. Suppose the gcd of the coefficients of $p(x)$ is 1. Then $p(x)$ is irreducible in $R[x]$ if and only if it is irreducible in $F[x]$. In particular, if $p(x)$ is a monic polynomial that is irreducible in $R[x]$, then $p(x)$ is irreducible in $F[x]$.
\end{cor}

\nl

\begin{thm}
$R$ is a UFD if and only if $R[x]$ is a UFD.
\end{thm}

\nl

\begin{cor}
If $R$ is a UFD, then a polynomial ring in an arbitrary number of variables with coefficients in $R$ is also a UFD.
\end{cor}

\nl

\begin{prop}
Let $F$ be a field and let $p(x)\in F[x]$. Then $p(x)$ has a factor of degree one if and only if $p(x)$ has a root in $F$.
\end{prop}

\nl

\begin{prop}
A polynomial of degree two or three is reducible over a field $F$ if and only if it has a root in $F$.
\end{prop}

\nl

\begin{prop}
Let $p(x) = a_nx^n+ a_{n-1}x^{n-1} + \cdots +a_0$ be a polynomial with integer coefficients. If $r/s\in \Q$ is in lowest terms and $r/s$ is a root of $p(x)$, then $r$ divides the constant term and $s$ divides the leading coefficient of $p(x)$. In particular, if $p(x)$ is a monic polynomial with integer coefficients and $p(d) \neq 0$ for all integers dividing the constant term of $p(x)$, then $p(x)$ has no roots in $\Q$.
\end{prop}

\nl

\begin{prop}
\hl{Let $I$ be a proper ideal in the integral domain $R$ and let $p(x)$ be a nonconstant monic polynomial in $R[x]$. If the image of $p(x)$ in $(R/I)[x]$ cannot be factored in $(R/I)[x]$ into two polynomials of smaller degree, then $p(x)$ is irreducible in $R[x]$.} \underline{\textit{(Use this with $\Z$ AND $\Z/p\Z$ to prove irreducibility.)}}
\end{prop} 

\nl

\begin{prop}\hl{\textit{(Eisenstein's Criterion)}}
Let $P$ be a prime ideal of the integral domain $R$ and let $f(x) = x^n + a_{n-1}x^{n-1}+\cdots + a_0$ be a polynomial in $R[x]$ where $n\geq 1$. Suppose $a_{n-1}, \ldots a_0$ are all elements of $P$ and suppose $a_0$ is not an element of $P^2$. Then $f(x)$ is irreducible in $R[x]$.
\end{prop}

\nl

\begin{prop}
The maximal ideals in $F[x]$ are the ideals $(f(x))$ generated by irreducible polynomials $f(x)$. In particular $F[x]/ (f(x))$ is a field if and only if $f(x)$ is irreducible.
\end{prop}

\nl

\begin{prop}
Let $g(x)$ be a nonconstant monic element of $F[x]$ and let
\[g(x) = f_1(x)^{n_1}f_2(x)^{n_2}\cdots f_k(x)^{n_k}\]
be its factorization into irreducible, where the $f_i(x)$ are distinct. Then we have the following isomorphism of rings:
\[F[x]/(g(x)) \cong F[x]/ (f_1(x)^{n_1}) \times F[x]/ (f_2(x)^{n_2}) \times \cdots F[x]/ (f_k(x)^{n_k}).\]
\end{prop}

\nl

\begin{prop}
If the polynomial $f(x)$ has roots $\al_1,\al_2,\ldots,\al_k$ in $F$, then $f(x)$ has $(x-\al_1)\cdots (x-\al_k)$ as a factor. In particular, a polynomial of degree $n$ in one variable has at most $n$ roots in $F$, even counted with multiplicity.
\end{prop}

\nl

\begin{prop}
A finite subgroup of the multiplicative group of a field is cyclic. In particular, if $F$ is a finite field, the the multiplicative group $F^\times$ of nonzero elements of $F$ is a cyclic group.
\end{prop}

\nl

\begin{cor}
Let $n\geq 2$ be an integer with factorization $n = p_1^{\al_1}p_2^{\al_2}\cdots p_r^{\al_r}$ in $\Z$, where $p_1,p_2,\ldots,p_r$ are distinct primes. We have the following isomorphism of (multiplicative) groups:
\begin{enumerate}
\item $(\Z/n\Z)\cong (\Z/p_1^{\al_1}\Z)^\times \times (\Z/p_2^{\al_2}\Z)^\times \times \cdots \times(\Z/p_r^{\al_r}\Z)^\times$
\item $(\Z/2^\al \Z)^\times$ is the direct product of a cyclic group of order 2 and a cyclic group of order $2^{\al -2}$, for all $\al \geq 2$
\item $(\Z/p^\al \Z)^\times$ is a cyclic group of order $p^{\al -1}(p-1)$, for all odd primes $p$.
\end{enumerate}
\end{cor}


%################################################################################
\section{Introduction to Module Theory}
\setcounter{thm}{0}

\begin{defn}
Let $R$ be a ring (not necessarily commutative nor with 1). A \textit{\textbf{left $R$-module}} or a \textit{left module over $R$} is a set $M$ together with
\begin{enumerate}
\item a binary operation $+$ on $M$ under which $M$ is an abelian group, and
\item an action of $R$ on $M$ (that is, a map $R\times M\ra M$) denoted by $rm$, for all $r\in R$ and for all $m\in M$ which satisfies
\begin{enumerate}
\item $(r + s)m = rm + sm$, \ \ \ for all $r,s\in R,\ m\in M$
\item $(rs)m = r(sm)$, \ \ \ for all $r,s\in R,\ m\in M$, and 
\item $r(m + n) = rm + rn$, \ \ \ for all $r,s\in R,\ m\in M$.
\end{enumerate}
If the ring $R$ has 1 we impose the additional axiom:
\begin{enumerate}
\item[(d)]  $1m = m$, \ \ \ for all $m\in M$.
\end{enumerate}
\end{enumerate}
\end{defn}

\nl

\begin{defn}
Let $R$ be a ring and let $M$ be an $R$-module. An $R$-\textit{\textbf{submodule}} of $M$ is a subgroup $N$ of $M$ which is closed under the action of ring elements. 
\end{defn}

\nl

\begin{prop}
\hl{\textit{(The Submodule Criterion)}} Let $R$ be a ring and let $M$ be an $R$-module. A subset $N$ of $M$ is a submodule of $M$ if and only if
\begin{enumerate}
\item $N\neq \es$, and
\item $x + ry\in N$ for all $r\in R$ and for all $x,y\in N$.
\end{enumerate}
\end{prop}

\nl

\begin{defn}
Let $R$ be a ring and let $M$ and $N$ be $R$-modules.
\begin{enumerate}
\item A map $\vphi: M\ra N$ is an $R$\textbf{\textit{-module homomorphism}} if it respects the $R$-module structures of $M$ and $N$, i.e.,
\begin{enumerate}
\item $\vphi(x + y) = \vphi(x) + \vphi(y)$, \ \ \ for all $x,y\in M$ and
\item $\vphi(rx) = r\vphi(x)$, \ \ \ for all $r\in R$, $x\in M$.
\end{enumerate}
\item An $R$-module homomorphism is an \textbf{\textit{isomorphism}} if it is both injective and surjective. The modules $M$ and $N$ are said to be \textbf{\textit{isomorphic}}, denoted $M\cong N$ if there is some $R$-module isomorphism $\vphi: M\ra N$.
\item If $\vphi:M\ra N$ is an $R$-module homomorphism, let $\ker(\vphi) = \{m\in M\ |\ \vphi(m) = 0\}$ and let $\vphi(M) = \{n\in N\ |\ n = \vphi(m)\text{ for some } m\in M\}$.
\item Let $M$ and $N$ be $R$-modules and define $\Hom_R(M,N)$ to be the set of $R$-module homomorphisms from $M$ to $N$.
\end{enumerate}
\end{defn}

\nl

\begin{prop}
Let $M$, $N$, and $L$ be $R$-modules
\begin{enumerate}
\item A map $\vphi: M\ra N$ is an $R$-module homomorphism if and only if $\vphi(rx + y) = r\vphi(x) + \vphi(y)$ for all $x,y\in M$ and $r\in R$.
\item Let $\vphi,\ \psi$ be elements of $\Hom_R(M,N)$. Define $\vphi + \psi $ by
\[(\vphi + \psi)(m) = \vphi(m) + \psi(m)\qquad\text{for all } m\in M.\]
Then $\vphi + \psi\in \Hom_R(M,N)$ and with this operation $\Hom_R(M,N)$ is an abelian group. If $R$ is a commutative ring the for $r\in R$ define $r\vphi$ by 
\[(r\vphi)(m) = r(\vphi(m))\qquad\text{for all } m\in M.\]
Then $r\vphi\in\Hom_R(M.N)$ and with this action of the commutative ring $R$ the abelian group $\Hom_R(M,N)$ is an $R$-module.
\item If $\vphi\in\Hom_R(L,M)$ and $\psi\in\Hom_R(M,N)$ then $\psi\circ\vphi\in\Hom_R(L,N)$.
\item With addition as above and multiplication defined as function composition, $\Hom_R(M,M)$ is an $R$-algebra.
\end{enumerate}
\end{prop}

\nl

\begin{defn}
The ring $\Hom_R(M,M)$ is called the \textbf{\textit{endomorphism ring of $M$}} and will often be denoted by $\End_R(M)$. Elements of $\End(M)$ are called \textbf{\textit{endomorphisms}}.
\end{defn}

\nl

\begin{prop}
Let $R$ be a ring, let $M$ be an $R$-module, and let $N$ be a submodule of $M$. The quotient group $M/N$ can be made into an $R$-module by defining an action of elements of $R$ by
\[r(x + N) = (rx) + N),\qquad\text{ for all }r\in R,\ x + N \in M/N.\]
The natural projection map $\pi:M\ra M/N$ is an $R$-module homomorphism with kernel $N$.
\end{prop}

\nl

\begin{defn}
Let $A$, $B$ be submodules of the $R$-module $M$. The \textit{sum} of $A$ and $B$ is the set 
\[A + B = \{a + b\ |\ a\in A,\ b\in B\}.\]
\end{defn}

\nl

\begin{defn}
Let $M$ be an $R$-module and let $N_1,\ldots,N_n$ be submodules of $M$.
\begin{enumerate}
\item The \textbf{\textit{sum}} of $N_1,\ldots,N_n$ is the set of all finite sums of elements form the sets $N_i:\ \{a_1+\cdots+a_n\ |\ a_i\in N_i\}$. Denote this sum by $N_1+\cdots +N_n$.
\item For any subset $A$ of $M$ let
\[RA = \{r_1a_1+\cdots+r_ma_m\ |\ a_i\in A,\ r_i \in R,\ m\in\Z^+\}.\]
If $A$ is finite we may write $Ra_1 + Ra_2+\cdots +Ra_m$. Call $RA$ th \textit{\textbf{submodule of $M$ generated by $A$}}. If $N$ is a submodule of $M$ and $N = RA$ for some subset $A$ of $M$, we call $A$ a set of generators or a generating set for $N$,. and we say that $N$ is generated by $A$.
\item A submodule $N$ of $M$ is \textbf{\textit{finitely generated}} if there is some finites subset $A$ of $M$ such that $N = RA$.
\item A submodule $N$ of $M$ is \textit{\textbf{cyclic}} if there exists an element $a\in M$ such that $N = Ra$, that is, if $N$ is generated by one element.
\end{enumerate}
\end{defn}

\nl

\begin{prop}
Let $N_1,N_2,\ldots,N_k$ be submodules of the $R$-module $M$. Then the following are equivalent
\begin{enumerate}
\item The map $\pi:N_1\times N_2\times \cdots \times N_k\ra N_1 + N_2 + \cdots + N_k$ defined by 
\[\pi(a_1,a_2,\ldots,a_k) = a_1 + a_2+\cdots + a_k\]
is an isomorphism (of $R$-modules)
\item $N_j\cap N_1+\cdots N_{j-1} + N_{j + 1} +\cdots +N_k = 0$ for all $j\in \{1,2,\ldots, k\}$.
\item Every $x\in N_1+\cdots + N_k$ can be written \textit{uniquely} in the form $a_1 + a_2 + \cdots + a_k$ for $a_i \in N_i$.
\end{enumerate}
\end{prop}

\nl

\begin{defn}
If an $R$-module $M = N_1 + N_2 + \cdots + N_k$ is the sum of submodules $N_1,N_2,\ldots,N_k$ of $M$ satisfying the equivalent conditions in the above proposition, then $M$ is said to be the \textit{\textbf{(internal) direct sum}} of $N_1, N_2, \ldots, N_k$ written
\[M = N_1 \oplus N_2 \oplus \cdots \oplus N_k.\]
\end{defn}

\nl

\begin{defn}
And $R$-module $F$ is said to be \textbf{\textit{free}} on the subset $A$ of $F$ if for every nonzero element $x$ of $F$, there exist unique nonzero elements $r_1,r_2,\ldots, r_n$ of $R$ and unique $a_1,a_2,\ldots, a_n$ in $A$ such that $x = r_1a_1 + r_2 a_2 + \cdots + r_n a_n$, for some $n\in \Z^+$. In this situation we say $A$ is a \textbf{\textit{basis}} or \textbf{\textit{set of free generators}} for $F$. If $R$ is a commutative ring the cardinality of $A$ is called the \textbf{\textit{rank}} of $F$.
\end{defn}

\nl

\begin{thm}
For any set $A$ there is a free $R$-module $F(A)$ on the set $A$ and $F(A)$ satisfies the following \textbf{\textit{universal property}}: if $M$ is any $R$-module and $\vphi: A\ra M$ is any map of sets, then there is a unique $R$-module homomorphism $\Phi:F(A) \ra M$ such that $\Phi(a) = \vphi(a)$, for all $a\in A$, that is, the following diagram commutes.

\begin{center}
\begin{tikzcd}[row sep = 2em, column sep = 3em]
A\arrow[r, "\iota"]\arrow[dr, swap, "\vphi"] & F(A)\arrow[d, "\Phi"]\\
 & M
\end{tikzcd}
\end{center}

\end{thm}

\nl

\begin{cor}\nl
\begin{enumerate}
\item If $F_1$ and $F_2$ are free modules on the same set $A$, there is a unique isomorphism between $F_1$ and $F_2$ which is the identity map on $A$.
\item If $F$ is any free $R$-module with basis $A$, then $F\cong F(A)$. In particular, $F$ enjoys the same universal property with respect to $A$ as $F(A)$ does in the previous theorem.
\end{enumerate}
\end{cor}



%################################################################################
\section{Vector Spaces}
\setcounter{thm}{0}

\begin{defn}
If $F$ is an field and $V$ is an $F$-module, then $V$ is called a \textit{vector space over $F$}.
\end{defn}

\nl

\begin{defn}\nl
\begin{enumerate}
\item A subset $S$ of $V$ is called a set of \textbf{\textit{linearly independent}} vectors if an equation $\al_1v_1+\cdots +\al_nv_n = 0$ with $\al_1,\ldots \al_n\in F$ and $v_1,\ldots, v_n\in S$ implies $\al_1 = \al_2 = \cdots = \al_n = 0$. \hl{(Note: an infinite set is linearly independent if this condition holds for any finite subset.)}
\item A \textit{basis} of a vector space $V$ is an \textbf{\textit{ordered set}} of linearly independent vectors which span $V$. In particular, two bases sill be considered different even if one is simply a rearrangement of the other. This is sometimes referred to as an \textit{ordered basis}.
\end{enumerate}
\end{defn}

\nl

\begin{prop}
Assume that $\A = \{v_1,v_2,\ldots, v_n\}$ spans the vector space $V$ but no proper subset of $\A$ spans $V$. Then $\A$ is a basis of $V$. \hl{In particular, any finitely generated vector space over $F$ is a free $F$-module.}
\end{prop}

\nl

\begin{thm}\hl{\textit{(A Replacement Theorem)}}
Assume $\A = \{a_1,a_2,\ldots,a_n\}$ is a basis for $V$ containing $n$ elements and $\{b_1,b_2,\ldots, b_m\}$ is a set of linearly independent vectors in $V$. Then there is an ordering $a_1,a_2,\ldots,a_n$ such that for each $k\in\{1,2,\ldots,m\}$ the set $\{b_1,\ldots, b_k, a_{k+1}, \ldots, a_n\}$ is a basis of $V$. In other words, the elements of $b_1,b_2,\ldots, b_m$ can be used to successively replace the elements of the basis $\A$, still retaining a basis. In particular $n\geq m$
\end{thm}

\nl

\begin{cor}\nl
\begin{enumerate}
\item Suppose $V$ has a finite basis with $n$ elements. Any set of linearly independent vectors has $\leq n$ elements. Any spanning set has $\geq n$ elements.
\item If $V$ has some finite basis, then any two bases of $V$ have the same cardinality.
\end{enumerate}
\end{cor}

\nl

\begin{defn}
If $V$ is a finitely generated $F$-module the cardinality of any basis is called the \textit{dimension} of $V$ and is denoted $\dim_F(V)$, or just $\dim(V)$ when $F$ is clear from the context, and $V$ is said to be \textit{finite dimensional over $F$}. If $V$ is not finitely generated, $V$ is said to be infinite dimensional.
\end{defn}

\nl

\begin{cor}
If $A$ is a set of linearly independent vectors in the finite dimensional vector space $V$, then there exists a basis of $V$ containing $A$
\end{cor}

\nl

\begin{thm}
If $V$ is an $n$ dimensional vector space over $F$, the $V\cong F^n$. In particular, any two finite dimensional vector spaces over $F$ of the same dimension are isomorphic.
\end{thm}

\begin{proof}
Let $v_1,v_2,\ldots,v_n$ be a basis for $V$. Define the map 
\[\vphi:F^n\ra V:(\al_1,\al_2,\ldots,\al_n)\mapsto\al_1v_1 + \al_2v_2+\cdots+\al_n v_n.\]
The map $\vphi$ is clearly $F$-linear, is surjective since the $v_i$ span $V$, and is injective since the $v_i$ are linearly independent, hence is an isomorphism.
\end{proof}

\nl

\begin{thm}
Let $V$ be a vector space over $F$ and let $W$ be a subspace of $V$. Then $V/W$is a vector space with $\dim(V) = \dim(W) + \dim(V/W)$.
\end{thm}

\nl

\begin{cor}
Let $\vphi:V\ra U$ be a linear transformation of vector spaces over $F$. Then $\ker(\vphi)$ is a subspace of $V$, $\vphi(V)$ is a subspace of $U$, and $\dim(V) = \dim(\ker(\vphi)) + \dim(\vphi(V))$.
\end{cor}

\nl

\begin{cor}
Let $\vphi:V\ra U$ be a linear transformation of vector spaces of the same finite dimension. Then the following are equivalent
\begin{enumerate}
\item $\vphi$ is an isomorphism
\item $\vphi$ is injective, i.e., $\ker(\vphi) = 0$
\item $\vphi$ is surjective
\item $\vphi$ sends a basis of $V$ to a basis of $W$.
\end{enumerate}
\end{cor}

\nl

\begin{defn}
If $\vphi:V\ra U$ is a linear transformation of vector spaces over $F$, $\ker(\vphi)$ is sometimes called the \textit{\textbf{null space}} of $\vphi$. and the dimension of $\ker(\vphi)$ is called the \textit{\textbf{nullity}} of $\vphi$. The dimension of $\vphi(V)$ is called the \textit{\textbf{rank}} of $\vphi$. If $\ker(\vphi) = 0$, then the transformation is said to be \textit{\textbf{nonsingular}}.
\end{defn}

\nl

\begin{defn}
The $m \times m$ matrix $A = (a_{ij})$ associated to the linear transformation $\vphi$ is said to \textit{represent} the linear transformation $\vphi$ with respect to the bases $\BB, \EE$. Similarly, $\vphi$ is the linear transformation represented by $A$ with respect to the bases $\BB, \EE$.
\end{defn}

\nl

\begin{thm}
Let $B$ be a vector space over $F$ of dimension $n$ and let $W$ be a vector space over $F$ of dimension $m$, with bases $\BB, \EE$ respectively. Then the map $\Hom_F(V, W)\ra M_{m\times n}(F)$ from the space of linear transformations from $v$ to $W$ to the space of $m\times n$ matrices with coefficients in $F$ defined by $\vphi\mapsto M_\BB^\EE(\vphi)$ is a vector space isomorphism. In particular, there is a bijective correspondence between linear transformations and their associated matrices with respect to a fixed choice of bases.
\end{thm}

\nl

\begin{cor}
The dimension of $\Hom_F(V,W)$ is $(\dim(V))(\dim(W))$.
\end{cor}

\nl

\begin{defn}
An $m\times n$ matrix $A$ is called \textit{\textbf{nonsingular}} if $Ax = 0$ with $x\in F^n$ implies $x = 0$.
\end{defn}

\nl

\begin{thm}
With notation as above $M_\BB^\EE(\vphi\circ \psi) = M_\BB^\EE(\vphi) M_\BB^\EE(\psi)$.
\end{thm}

\nl

\begin{cor}
Matrix multiplication is associative and distributive. An $n\times n$ matrix $A$ is nonsingular if and only if it is invertible.
\end{cor}

\nl

\begin{cor}\nl
\begin{enumerate}
\item If $\BB$ is a basis of the $n$-dimensional space $V$, the map $\vphi\mapsto M_\BB^\BB(\vphi)$ is a ring and a vector space isomorphism of $\Hom_F(V,V)$ onto the space $M_n(F)$ of $n\times n$ matrices with coefficients in $F$.
\item $GL(V)\cong GL_n(F)$ where $\dim(V) = n$. 
\end{enumerate}
\end{cor}

\nl

\begin{defn}
If $A$ is any $m\times n$ matrix with entries of $F$, the \textit{\textbf{row rank}} of $A$ is the maximal number of linearly independent rows of $A$.
\end{defn}

\nl

\begin{defn}
Two $n\times n$ matrices $A$ and $B$ are said to be \textit{\textbf{similar}} if the is an invertible $n\times n$ matrix $P$ such that $P\inv A P = B$. Two linear transformations $\vphi$ and $\psi$ from a vector space $V$ to itself are said to be \textit{similar} if the is a nonsingular linear transformation $\xi$
\end{defn}

\nl

\begin{defn}\nl
\begin{enumerate}
\item For $V$ any vector space over $F$ let $V^* = \Hom_F(V,F)$ be the space of linear transformations from $V$ to $F$, called the \textit{\textbf{dual space}} of $V$. Elements of $V^*$ are called \textit{\textbf{linear functionals}}.
\item If $\BB  = \{v_1,v_2,\ldots,v_n\}$ is a basis of the finite dimensional space $V$, define $v_i^* \in V^*$ for each $i = 1..n$ by its action on the basis $\BB$:
\[v_i^*(v_j) = \begin{cases}1, & \text{if } i = j\\
0, & \text{if } i \neq j\end{cases}\qquad 1\leq j\leq n.\]
\end{enumerate}
\end{defn}

\nl

\begin{prop}
With notations as above, $\{v_1^*,v_2^*,\ldots,v_n^*\}$ is a basis of $V^*$. In particular, if $V$ is finite dimensional then $V^*$ has the same dimension as $V$.

\begin{proof}
(Copied from D\&F) Observe that since $V$ is finite dimensional, $\dim(V^*) = \dim(\Hom_F(V,F)) = \dim(V) = n$ (\textcolor{red}{Corollary 11.11}), so since there are $n$ of the $v_i^*$'s it suffices to prove that they are linearly independent. If
\[\al_1v_1^* + \al_2v_2^* + \cdots + \al_nv^n = 0\quad \text{in } \Hom_F(V,F),\]
then applying this element to $v_i$ and using th equation above gives us that $\al_i = 0$. Since $i$ is arbitrary these elements are linearly independent.
\end{proof}
\end{prop}

\nl

\begin{defn}
The basis $\{v_1^*,v_2^*,\ldots,v_n^*\}$ of $V^*$ is called the \textit{\textbf{dual basis}} to  $\{v_1,v_2,\ldots,v_n\}$.
\end{defn}

\nl

\begin{thm}
There is a natural injective linear transformation from $V$ to $V^{**}$. If $V$ is finite dimensional then this linear transformation is an isomorphism. 

\textit{Sketch of proof.} Let $v\in V$ and define the evaluation map $E_v:V^*\ra F:f\mapsto f(v)$. This is a linear transformation from $V^*$ to $F$, and so is an element of $\Hom_F(V^*, F) = V^{**}$. This defines a natural map $\vphi: V\ra V^{**}:v\mapsto E_v$. This map is injective for all $V$ and $\vphi$ is an isomorphism if $V$ is finite dimensional.
\end{thm}

\nl

\begin{thm}
Let $V,W$ be finite dimensional vector spaces over $F$ with bases $\BB, \EE$, respectively and let $\BB^*,\EE^*$ be the dual bases . Fix some $\vphi\in \Hom(V,W)$. Then for each $f\in W^*$, the composite $f\circ \vphi$ is a linear transformation from $V$ to $F$, that is $f\circ \vphi\in V^*$. Thus, we can define a map $\vphi^*:W^* \ra V^*:f\mapsto f\circ \vphi$ (called the \textit{\textbf{pullback}} of $f$) and the matrix $M_{\EE^*}^{\BB^*}(\vphi^*)$ is the transpose of th matrix $M_\BB^\EE(\vphi)$.
\end{thm}

\nl

\begin{cor}
For any matrix $A$, the row rank of $A$ equals the column rank of $A$.
\end{cor}

\nl

\begin{defn}\nl
\begin{enumerate}
\item A map $\vphi:V_1\times V_2\times \cdots \times V_n\ra W$ is called \textit{\textbf{multilinear}} if for each fixed $i$ and fixed $i$ and fixed elements $v_j\in V_j$, $j\neq i$, the map
\[V_i \ra W\qquad \text{defined by}\qquad x\mapsto \vphi(v_1,\ldots,v_{i-1},x,v_{i+1},\ldots, v_n)\]
is an $R$-module homomorphism. If $V_i = V$, $i = 1,2,\ldots, n$, then $\vphi$ is called an $n$\textit{-multilinear function on $V$}, and if in addition $W = R$, $\vphi$ is called an \textit{$n$-multilinear form on $V$}.

\item An $n$-multilinear function $\vphi$ on $V$ is called \textit{alternating} if $\vphi(v_1, v_2,\ldots, v_n) = 0$ whenever $v_i = v_{i + 1}$ for some $i\in \{1,2,\ldots, n-1\}$. The function $\vphi$ is called \textit{symmetric} if interchanging $v_i$ and $v_j$ for any $i$ and $j$ in $(V_1,v_2,\ldots, v_n)$ does not alter the value of $\vphi$ on this $n$-tuple.
\end{enumerate}
\end{defn}

\nl

\begin{prop}
Let $\vphi$ be an $n$-multilinear alternating function on $V$. Then 
\begin{enumerate}
\item $\vphi(v_1,\ldots, v_{i-1}, v_{i + 1}, v_i, v_{i + 2}, \ldots, v_n) = -\vphi(v_1, v_2, \ldots, v_n)$ for any $i\in \{1,2,\ldots, n-1\}$.

\item For each $\sigma\in S_n$, $\vphi(v_{\sigma(1)}, v_{\sigma(2)},\ldots, v_{\sigma(n)}) = sgn(\sigma)\vphi(v_1, v_2, \ldots, v_n)$.

\item If $v_i = v_j$ for any pair of distinct $i,j\in \{1,2,\ldots, v_n\}$ then $\vphi(v_1, v_2, \ldots, v_n) = 0$.

\item If $v_i$ is replaced by $v_i + \al v_j$ in $(v_1,v_2,\ldots,v_n)$ for any $j\neq i$ and any $\al \in R$, the value of$\vphi$ on this $n$-tuple is not changed.
\end{enumerate}
\end{prop}

\nl

\begin{prop}
Assume $\vphi$ is an $n$-multilinear alternating function on $V$ and that for some $v_1,v_2,\ldots,v_n$ and $w_1,w_2,\ldots,w_n\in V$ and some $\al_{ij}\in R$ we have
\begin{align*}
w_1 &= \al_{11}v_1 + \al_{21}v_2 + \cdots + \al_{n1}v_n\\
w_2 &= \al_{12}v_1 + \al_{22}v_2 + \cdots + \al_{n2}v_n\\
\vdots\\
w_n &= \al_{1n}v_1 + \al_{2n}v_2 + \cdots + \al_{nn}v_n.\\
\end{align*}
Then 
\[\vphi(w_1,w_2,\ldots,w_n) = \sum_{\sigma\in S_n} sgn(\sigma)\al_{\sigma(1)1}\al_{\sigma(2)2}\cdots\al_{\sigma(n)n}\vphi(v_1,v_2,\ldots,v_n).\]
\end{prop}

\nl

\begin{defn}
An $n\times n$ \textit{\textbf{determinant function}} on $R$ is any function 
\[\det:M_{n\times n}(R)\ra R\]
that satisfies the following two axioms:
\begin{enumerate}
\item $\det$ is an $n$-multilinear alternating form on $R^n( = V)$, where the $n$-tuples are the $n$ columns of the matrices in $M_{n\times n}(R)$.
\item $\det(I) = 1$.
\end{enumerate}
\end{defn}

\nl

\begin{thm}
There is a unique $n\times n$ determinant function on $R$ and it can be computed for any $n\times n$ matrix $(\al_{ij})$ by the formula:
\[det(\al_{ij}) = \sum_{\sigma\in S_n} sgn(\sigma) \al_{\sigma(1)1} \al_{\sigma(2)2} \cdots \al_{\sigma(n)n}\]
\end{thm}

\nl

\begin{cor}
The determinant is an $n$-multilinear function of the rows of $M_{n\times n}(R)$ and for any $n\times n $ matrix $A$, $\det(A) = \det(A^t)$.
\end{cor}

\nl

\begin{thm}\textit{(Cramer's Rule)}
If $A_)1,A_23,\ldots, A_n$ are the columns of an $n\times n$ matrix $A$ and $B = \be_1A_1 + \be_2A_2 + \cdots + \be_nA_n$, for some $\be_1,\ldots, \be_n\in R$, then
\[\be_i\det(A) = \det(A_1,\ldots,A_{i-1}, B, A_{i+1},\ldots, A_n).\]
\end{thm}

\nl

\begin{cor}
If $R$ is an integral domain, then $\det(R) = 0$ for $A\in M_n(R)$ if and only if the columns of $A$ are $R$-linearly dependent as elements of the free $R$-module of rank $n$. Also $\det(A) = 0$ if and only if the rows of $A$ are $R$-linearly dependent.
\end{cor}

\nl

\begin{thm}
For matrices $A, B\in M_{n\times n}(R)$, $\det(A,B) = \det(A)\det(B)$.
\end{thm}

\nl

\begin{defn}
Let $A = (\al_{ij})$ be an $n\times n$ matrix. For each $i,\ j$, let $A_{ij}$ be the $n-1\times n-1$ matrix obtained from $A$ by deleting its $i^{th}$ row and $j^{th}$ column. Then $(-1)^{i + j}\det(A_{ij})$ is called the \textit{\textbf{$ij$ cofactor of $A$.}}
\end{defn}

\nl

\begin{thm}\textit{(The Cofactor Expansion Formula along the $i^{th}$ row)}
If $A = (\al_{ij})$ is an $n\times n$ matrix, then for each fixed $i\in \{1,2,\ldots n\}$ the determinant of $A$ can be computed from the formula
\[\det(A) = (-1)^{i+1}\al_{i1}\det(A_{i1}) + (-1)^{i+2}\al_{i2}\det(A_{i2}) + \cdots + (-1)^{i+n}\al_{in}\det(A_{in}).\]
\end{thm}

\nl

\begin{thm}\textit{(Cofactor Formula for the Inverse of a Matrix)} Let $A = (\al_{ij})$ be an $n\times n$ matrix and let $B$ be the transpose of is matrix of cofactors, i.e., $B = (\be_{ij})$, where $\be_{ij} = (-01)^{i + j}\det(A_{ji})$, $1\leq ii,j\leq n$. Then $AB = BA = \det(A)I$. Moreover, $\det(A)$ is a unit in $R$ if and only if $A$ is a unit in $M_{n\times n}(R)$; in this case the matrix $\frac{1}{\det(A)} B$ is the inverse of $A$.
\end{thm}

%################################################################################
\section{Modules over Principal Ideal Domains}
\setcounter{thm}{0}

\begin{defn}\nl
\begin{enumerate}
\item The left $R$ module $M$ is said to be a \textit{\textbf{Noetherian $R$-module}} or to satisfy the \textit{\textbf{ascending chain condition on submodules}} if there are no infinite increasing chains of submodules (any increasing chain stabilizes).
\item The ring $R$ is said to be \textit{Noetherian} if it is Noetherian as a left module over itself.
\end{enumerate}
\end{defn}

\nl

\begin{thm}
Let $R$ be a ring and let $M$ be a lift $R$-module. Then the following are equivalent:
\begin{enumerate}
\item \hl{$M$ is a Noetherian $R$-module.}
\item Every nonempty set of submodules of $M$ contains a maximal element under inclusion.
\item \hl{Every submodule of $M$ is finitely generated.}
\end{enumerate}
\end{thm}

\nl

\begin{cor}
If $R$ is a $PID$ then every nonempty set of ideal of $R$ has a maximal element and $R$ is a Noetherian ring.
\end{cor}

\nl

\begin{prop}
Let $R$ be an integral domain and let $M$ be a free $R$-module of rank $n<\infty$. Then any $n + 1$ elements of $M$ are $R$-linearly dependent.
\end{prop}

\nl

\begin{defn}
For any integral domain $R$ the \textit{\textbf{rank}} of an $R$-module $M$ is the maximum number of $R$-linearly independent elements of $M$.
\end{defn}

\nl

\begin{thm}
Let $R$ be a PID, let $M$ be a free $R$-module of finite rank $n$ and let $N$ be a submodule of $M$. Then
\begin{enumerate}
\item $N$ is free of rank $m$, $m\leq n$
\item there exists a basis $y_1,y_2,\ldots,y_n$ of $M$ so that $a_1y_1,\ldots,a_my_m$ is a basis of $N$ where $a_1, a_2, \ldots, a_m$ are nonzero elements of $R$ with the divisibility relations
\[a_1\ |\ a_2\ |\ \cdots\ |\ a_m.\]
\end{enumerate}
\end{thm}

\nl

\begin{thm}\textit{\hl{(Fundamental Theorem, Existence: Invariant Factor Form)}}
Let $R$ be a PID and let $M$ be a finitely generated $R$-module.
\begin{enumerate}
\item Then $M$ is isomorphic to the direct sum of finitely many cyclic modules. More precisely,
\[M\cong R^r\oplus R/(a_1) \oplus R/(a_2) \oplus \cdots \oplus R/(a_m)\]
for some integer $r\geq 0$ and nonzero elements $a_1, a_2,\ldots, a_m$ of $R$ which are not units in $R$ an which satisfy the divisibility relations 
\[a_1\ |\ a_2\ |\ \cdots\ |\ a_m.\]

\item $M$ is torsion free if and only if $M$ is free.
\item In the decomposition in (1) the set of torsion elements,
\[\Tor(M) \cong R/(a_1) \oplus R/(a_2) \oplus \cdots \oplus R/(a_m)\]
(Recall: $\Tor(M) = \{m\in M\ |\ rm = 0\text{ for some nonzero }r\in R\}$). In particular, $M$ is a torsion module if and only if $r = 0$ and in this case the the annihilator of $M$ is the ideal $(a_m)$.
\end{enumerate}
\end{thm}

\nl

\begin{defn}
The integer $r$ in the previous theorem is called the \textit{free rank} or the \textit{Betti number} of $M$ and the elements $a_1, a_2, \ldots, a_m\in R$ are called the \textit{\textbf{invariant factors}} of $M$.
\end{defn}

\nl

\begin{thm}\textit{\hl{(Fundamental Theorem, Existence: Elementary Divisor Form)}} 
Let $R$ be a PID and let $M$ be a finitely generated $R$-module. Then $M$ is the direct sum of a finite number of cyclic module whose annihilators are either $(0)$ or generated by powers of the primes in $R$, i.e.,
\[M\cong R^r \oplus R/(p_1^{\al_1})\oplus R/(p_2^{\al_2}) \oplus \cdots \oplus R/(p_t^{\al_t})\]
where $r\geq 0$ is an integer and $p_1^{\al_1},\ldots, p_t^{\al_t}$ are positive powers of (not necessarily distinct) primes in $R$.
\end{thm}

\nl

\begin{defn}
Let $R$ be a PID and let $M$ be a finitely generated $R$-module as in the previous theorem. The prime powers $p_1^{\al_1},\ldots, p_t^{\al_t}$ are called the \textit{\textbf{elementary divisors}} of $M$.
\end{defn}

\nl

\begin{thm}\hl{\textit{(The Primary Decomposition Theorem)}} Let $R$ be a PID and let $M$ be a nonzero torsion $R$-module with nonzero annihilator $a$. Suppose the factorization of $A$ into distinct prime powers in $R$ is 
\[a = up_1^{\al_1}p_2^{\al_2}\cdots p_n^{\al_n}\]
and let $N_i = \{x\in M\ |\ p_i^{\al_i}x = 0\}$. $1 \leq i\leq n$. Then $N_i$ is a submodule of $M$ with annihilator $p_i^{\al_i}$ and is the submodule of $M$ of all the elements annihilated by some power of $p_i$. We have
\[M\cong N_1\oplus N_2\oplus \oplus \cdots \oplus N_n.\]
If $M$ is finitely generated then each $N_i$ is the direct sum of finitely many cyclic module whose annihilators are divisors of $p_i^{\al_i}$.
\end{thm}

\nl

\begin{defn}
The submodule $N_i$ given in the previous theorem is called the $p_i$\textit{-primary component} of $M$.
\end{defn}

\nl

\begin{lem}
Let $R$ be a PID and let $p$ be a prime in $R$. Let $F$ denote the field $R/(p)$.
\begin{enumerate}
\item Let $M = R^r$. Then $M/pM \cong F^r$.
\item Let $M = R/(a)$ where $a$ is a nonzero element of $R$. Then 
\[M/pM \cong \begin{cases}F & \text{if $p$ divides $a$ in $R$}\\ 0 &\text{if $p$ does not divide $a$ in $R$.}\end{cases}\]
\item Let $M\cong R/(a_1)\oplus R/(a_2)\oplus \cdots \oplus R/(a_k)$ where each $a_i$ is divisible by $p$. Then $M/pM \cong F^k$.
\end{enumerate}
\end{lem}

\nl

\begin{thm}\hl{\textit{(Fundamental Theorem, Uniqueness)}}
Let $R$ be a PID.
\begin{enumerate}
\item Two finitely generated $R$-modules $M_1$ and $M_2$ are isomorphic if and only if they have the same free rank and list of invariant factors.
\item Two finitely generated $R$-modules $M_1$ and $M_2$ are isomorphic if and only if they have the same free rank and the same list of elementary divisors.
\end{enumerate}
\end{thm}

\nl

\begin{cor}
Let $R$ be a PID and let $M$ be a finitely generated $R$-module.
\begin{enumerate}
\item The elementary divisors of $M$ are the prime power factors of the invariant factor of $M$.
\item The largest invariant factor of $M$ is the product of the larges of the distinct prime powers among the elementary divisors of $M$, the next largest invariant factor is the product of the largest of the distinct prime powers among the remaining elementary divisors of $M$, and so on.
\end{enumerate}
\end{cor}

\nl

\begin{cor}\textit{(The Fundamental Theorem of Finitely Generated Abelian Groups)}
See \textcolor{red}{Theorem 5.3} and \textcolor{red}{Theorem 5.5}.
\end{cor}

\nl

\begin{defn}\nl
\begin{enumerate}
\item An element $\lambda$ of $F$ is called an \textit{\textbf{eigenvalue}} of a linear transformation $T$ if there is a nonzero vector $v\in V$ such that $T(v) = \lambda v$. In this situation $v$ is called an \textit{\textbf{eigenvector}} of $T$ with corresponding eigenvalue $\lambda$.

\item If $A$ is an $n\times n$ matrix with coefficients in $F$, and element $\lambda$ is called an \textit{eigenvalue} of $A$ with corresponding eigenvector $v$ is $V$ is a nonzero $n\times 1$ column vector such that $Av\ = \lambda v$.

\item If $\lambda$ is an eigenvalue of the linear transformation $T$, the set $\{v\in V\ |\ T(v) = \lambda v\}$ is called the \textit{\textbf{eigenspace}} of $T$ corresponding to the eigenvalue $\lambda$. Similarly, if $\lambda$ is an eigenvalue of the $n\times n$ matrix $A$, the set of $n\times 1$ matrices $v$ with $Av = \lambda v$ is called the \textit{eigenspace} of $A$ corresponding to the eigenvalue $\lambda$.
\end{enumerate}
\end{defn}

\nl

\begin{defn}
The determinant of a linear transformation from $V$ to $V$ is the determinant of any matrix representing the linear transformation.
\end{defn}

\nl

\begin{prop}
The following are equivalent:
\begin{enumerate}
\item $\lambda$ is an eigenvalue of $T$.
\item $\lambda I - T$ is a singular linear transformation.
\item $\det(\lambda I - T) = 0$.
\end{enumerate}
\end{prop}

\nl

\begin{defn}
Let $x$ be an indeterminate over $F$. The polynomial $\det(xI - T)$ is called the \textit{\textbf{characteristic polynomial}}of $T$ and will be denoted $c_T(x)$. If $A$ is an $n\times n$ matrix with coefficients in $F$, $\det(xI- A)$ is called the \textit{characteristic polynomial of $A$} and will be denoted $c_A(x)$.
\end{defn}

\nl

\begin{defn}
The unique monic polynomial which generates the ideal $Ann(V)$ in $F[x]$ is called the \textit{\textbf{minimal polynomial}} of $T$ and will be denoted $m_T(x)$. The unique monic polynomial of smallest degree which when evaluated at the matrix $A$ is the zero matrix is called the \textit{minimal polynomial} of $A$  and will be denoted $m_A(x)$.
\end{defn}
\nl\\
\textbf{Note:} Since $V$ is finite dimensional, we know that $V$ is a finitely generated module over $F$. So $V$ is torsion over $F[x]$ and we have that
\[V\cong F[x]/(a_1(x)) \oplus F[x]/(a_2(x))\oplus \cdots \oplus F[x]/(a_m(x))\]
where the $a_i(x)$ are subject to the divisibility relations
\[a_1(x)\ |\  a_2(x)\ |\ \cdots\ |\  a_m(x).\]
These $a_i(x)$ are called the invariant factors of $V$.

\nl

\begin{prop}
The minimal polynomial $m_T(x)$ is the largest invariant factor of $V$. All the invariant factors of $V$ divide $m_T(x)$.
\end{prop}

\nl

\begin{defn}
Let $a(x) = x^k + b_{k - 1}x^{k - 1} + \cdots + b_1 x + b_0$ be any monic polynomial in $F[x]$. The \textit{\textbf{companion matrix}} of $a(x)$ is the $k\times k$ matrix with 1's down the first subdiagonal, $-b_0, -b_1, \ldots, -b_{k - 1}$ down the last column and zeros elsewhere. The companion matrix of $a(x)$ will be denoted $\CC_{a(x)}$.
\[\CC_{a(x)} = \begin{pmatrix}
0 & 0 & \cdots & \cdots & \cdots & -b_0\\
1 & 0 & \cdots & \cdots & \cdots & -b_1\\
0 & 1 & \cdots & \cdots & \cdots & -b_2\\
0 & 0 & \ddots &  &  & \vdots\\
\vdots & \vdots & & \ddots  &  & \vdots\\
0 & 0 & \cdots & \cdots & 1 & -b_{k - 1}\\
\end{pmatrix}\]
\end{defn}



\nl

\begin{defn}\nl
\begin{enumerate}
\item A matrix is said to be in \textit{\textbf{rational canonical form}} if it is the direct sum of companion matrices for monic polynomials $a_1(x), \ldots, a_m(x)$ of degree at least one with $a_1(x)\ |\  a_2(x)\ |\ \cdots\ |\  a_m(x).$ The polynomials $a_i(x)$ are called the \textit{invariant factors} of the matrix. Such a matrix is also said to be a \textit{\textbf{block diagonal}} matrix with block of the companion matrices for the $a_i(x)$.
\[\begin{pmatrix}
\CC_{a_1(x)} & & & \\
& \CC_{a_1(x)} & & \\
& & \ddots & \\
& & & \CC_{a_m(x)}
\end{pmatrix}\]
\item A \textit{\textbf{rational canonical form}} for a linear transformation $T$ is a matrix representing $T$ which is in rational canonical form.
\end{enumerate}
\end{defn}

\nl

\begin{thm}\hl{\textit{(Rational Canonical Form for Linear Transformations)}}
Let $V$ be a finite dimensional vector space over the field $F$ and let $T$ be a linear transformation of $V$.
\begin{enumerate}
\item There is a basis for $V$ with respect to which the matrix for $T$ is in rational canonical form.
\item The rational canonical form is unique
\end{enumerate}
\end{thm}

\nl

\begin{thm}
Let $S$ and $T$ be linear transformations of $V$. Then the following are equivalent:
\begin{enumerate}
\item $S$ and $T$ are similar linear transformations
\item the $F[x]$-modules obtained from $V$ via $S$ and via $T$ are isomorphic $F[x]$-modules
\item $S$ and $T$ have the same rational canonical form.
\end{enumerate}
\end{thm}

\nl

\begin{thm}\hl{\textit{(Rational Canonical Form for Matrices)}}
Let $A$ be a $n\times n$ matrix over a filed $F$.
\begin{enumerate}
\item The matrix $A$ is similar to a matrix in rational canonical form.
\item The rational canonical form of $A$ is unique.
\end{enumerate}
\end{thm}

\nl

\begin{defn}
The \textit{invariant factors} of an $n\times n$ matrix over a field $F$ are the invariant factors of its rational canonical form.
\end{defn}

\nl

\begin{thm}
Let $A$ and $B$ be $n\times n$ matrices over a field $F$. Then $A$ and $B$ are similar if and only if $A$ and $B$ have the same rational canonical form.
\end{thm}

\nl

\begin{cor}
Let $A$ and $B$ be two $n\times n$ matrices over a field $F$ and suppose $F$ is a subfield of the field $K$.
\begin{enumerate}
\item The rational canonical form of $A$ is the same whether it is computed over $K$ or over $F$. The minimal and characteristic polynomials and the invariant factors of $A$ are the same whether $A$ is considered as a matrix over $F$ or as a matrix over $K$.
\item The matrices $A$ and $B$ are similar over $K$ if and only if they are similar over $F$.
\end{enumerate}
\end{cor}

\nl

\begin{lem}
Let $a(x)\in F[x]$ be any monic polynomial.
\begin{enumerate}
\item The characteristic polynomial of the companion matrix of $a(x)$ is $a(x)$.
\item If $M$ is the block diagonal matrix
\[\begin{pmatrix}
A_1 & 0 & \cdots & 0\\
0 & A_2 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & A_k
\end{pmatrix}\]
given by the direct sum of matrices $A_1, A_2, \ldots, A_k$ then the characteristic polynomial of $M$ is the product of the characteristic polynomials of $A_1, A_2, \ldots, A_k$.
\end{enumerate}
\end{lem}

\nl

\begin{prop}
Let $A$ be an $n\times n$ matrix over the field $F$.
\begin{enumerate}
\item The characteristic polynomial of $A$ is the product of all the invariant factors of $A$.
\item \hl{\textit{(The Cayley-Hamilton Theorem)}} The minimal polynomial of $A$ divides the characteristic polynomial of $A$.
\item The characteristic polynomial of $A$ divides some power of the minimal polynomial of $A$. In particular these polynomials have the same roots, not counting multiplicities.
\end{enumerate}
\end{prop}

\nl

\begin{thm}
Let $A$ be an $n\times n$ matrix over the field $F$. Using the three elementary rows and column operations, the $n\times n$ matrix $xI - A$ with entries from $F[x]$ can be put into the diagonal \textit{\textbf{Smith Normal Form}} given by 
\[\begin{pmatrix}
1 & & & & & & \\
& \ddots & & & & & \\
& & 1 & & & & \\
& & & a_1(x) & & & \\
& & & & a_2(x) & & \\
& & & & & \ddots & \\
& & & & & & a_m(x)
\end{pmatrix}\]
\end{thm}

\nl

\begin{defn}
The $k\times k$ matrix with $\lambda$ along the main diagonal and 1 along the first superdiagonal is called the $k\times k$ \textit{elementary Jordan matrix with eigenvalue $\lambda$} or the \textit{Jordan block of size $k$ with eigenvalue $\lambda$}.
\end{defn}

\[\begin{pmatrix}
\lambda & 1 & & & \\
 & \lambda & \ddots & &\\
 & & \ddots & 1 & \\
 & & & \lambda & 1\\
 & & & & \lambda
\end{pmatrix}\]

\begin{defn}\nl
\begin{enumerate}
\item A matrix is said to be in \textit{\textbf{Jordan canonical form}} if it is a block diagonal matrix with Jordan blocks along the diagonal.

\item A \textbf{\textit{Jordan canonical form}} for a linear transformation $T$ is a matrix representing $T$ which is in Jordan canonical form.
\end{enumerate}
\end{defn}

\nl

\begin{thm}\hl{\textit{(Jordan Canonical Form for Linear Transformations)}} Let $V$ be a finite dimensional vector space over the field $F$ and let $T$ be a linear transformation of $V$. Assume that $F$ contains all the eigenvalues of $T$.
\begin{enumerate}
\item There is a basis for $V$ with respect to which the matrix for $T$ is in Jordan canonical form.
\item The Jordan canonical for for $T$ is unique up to a permutation of the Jordan blocks along the diagonal.
\end{enumerate}
\end{thm}

\nl

\begin{thm}\hl{\textit{(Jordan Canonical Form for Matrices)}} Let $A$ be a $n\times n$ matrix over the field $F$ and assume that $F$ contains all the eigenvalues of $A$.
\begin{enumerate}
\item The matrix $A$ is similar to a matrix in Jordan canonical form.
\item The Jordan canonical for for $A$ is unique up to a permutation of the Jordan blocks along the diagonal.
\end{enumerate}
\end{thm}

\nl

\begin{cor}\nl
\begin{enumerate}
\item If a matrix $A$ is similar to a diagonal matrix $D$, then $D$ is the Jordan canonical form of $A$.
\item Two diagonal matrices are similar if and only if their diagonal entries are the same up to a permutation.
\end{enumerate}
\end{cor}

\nl

\begin{cor}
If $A$ is an $n\times n$ matrix with entries from $F$ and $F$ contains all the eigenvalues of $A$, then $A$ is similar to a diagonal matrix over $F$ if and only if the minimal polynomial of $A$ has no repeated roots.
\end{cor}

